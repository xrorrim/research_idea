# how to quantize kv with int8

- hybrid quantization ( fp16 + int8 )? 中间的小区间还会被拉大

    - 不拉小区域？ “没道理”

- 回看没有zero point的那个代码

- 分隐藏层压 怎么存？

    - 比如qwen2: head* hidden* layer * 256 非常之小，随便存

# 压缩 fp16 kvcache

- 做实验

- 需不需要分指数小数压？